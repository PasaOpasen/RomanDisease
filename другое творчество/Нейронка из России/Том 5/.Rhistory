fit(X_train, y_train,
batch_size = 128,
epochs = 20,
validation_data = list(X_test, y_test))
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting2.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting2.R')
first_inds
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting2.R')
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.01)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 30,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 5,
factor = 0.5
)
)
)
save_model_hdf5(model, 'fit2_30epochs_1.76val_loss.h5', overwrite = TRUE, include_optimizer = TRUE)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 30,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 5,
factor = 0.5
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.7) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.02)
)
model
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 30,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 3,
factor = 0.5
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.7) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.015)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 50,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 2,
factor = 0.7
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.02)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 50,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 1,
factor = 0.7
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.1)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 35,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 1,
factor = 0.7
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.05)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 35,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 1,
factor = 0.7
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.03)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 35,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 1,
factor = 0.7
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid", return_sequences = T) %>%
layer_lstm(units = 64, recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.01)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 35,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 1,
factor = 0.7
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid", return_sequences = T, dropout = 0.4) %>%
layer_lstm(units = 128, recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.01)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 35,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 1,
factor = 0.7
)
)
)
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid", return_sequences = T, dropout = 0.4) %>%
layer_lstm(units = 128, recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.1)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 35,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 1,
factor = 0.7
)
)
)
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/tokenize.R')
warnings()
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/base_model.R')
library(keras)
load('arrays 50 5.rdata')
#all_inds = sample(c(1,2,3), size = dim(x)[1], replace = T, prob = c(0.7,0.2,0.1))
first_inds = ifelse(1:dim(x)[1] > 0.3*dim(x)[1], 1, 2)
all_inds = sample(c(2,3), size = sum(first_inds==2), replace = T, prob = c(0.6,0.4))
first_inds[first_inds == 2] = all_inds
all_inds = first_inds
train_inds = all_inds == 1
val_inds = all_inds == 2
test_inds = all_inds == 3
X_train = x[train_inds,,]
y_train = y[train_inds,]
X_test = x[val_inds,,]
y_test = y[val_inds,]
model <- keras_model_sequential() %>%
layer_lstm(units = 128, input_shape = c(maxlen, length(chars)),
recurrent_activation = "sigmoid") %>%
#layer_batch_normalization() %>%
layer_dropout(rate = 0.5) %>%
layer_dense(units = length(chars), activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(lr = 0.01)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 30,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 3,
factor = 0.5
)
)
)
model %>%
fit(X_train, y_train,
batch_size = 128,
epochs = 30,
validation_data = list(X_test, y_test),
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "val_loss",
patience = 3,
factor = 0.5
)
)
)
library(keras)
library(stringr)
text_path = 'Texts'
file_name = 'text.txt'
path = file.path(getwd(),text_path, file_name)
text <- tolower(readChar(path, file.info(path)$size))
cat("Text length:", nchar(text), "\n")
count =  nchar(text)
cat("Text length:",count, "\n")
if(count >= 60){
sentence = text[(count-60):count]
}else{
how = 60-count
sentence = paste0(rep(' ',how), text)
}
if(count >= 60){
sentence = text[(count-60):count]
}else{
how = 60-count
sentence = paste0(paste0(rep(' ',how)), text)
}
paste0(rep(' ',how))
q = paste0(rep(' ',how))
q[1]
q[2]
paste0(rep(' ',how), sep='')
paste("A", 1:6, sep = "")
paste("the", "quick", "brown", "fox", "jumps", sep=" ")
paste(rep(' ',how), sep=" ")
paste0(rep("2",how))
if(count >= 60){
sentence = text[(count-60):count]
}else{
how = 60-count
sentence = paste0(paste0(rep(' ',how), collapse = ''), text)
}
if(count >= 60){
sentence = text[(count-60):count]
}else{
how = 60-count
sentence = paste0(paste0(rep('',how), collapse = ' '), text)
}
nchar(sentence)
if(count >= 60){
sentence = text[(count-60):count]
}else{
how = 60-count
sentence = paste0(paste0(rep('',how+1), collapse = ' '), text)
}
nchar(sentence)
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
sentence
sampled[1,,]
rowSums(sampled[1,,])
text <- tolower(readChar(path, file.info(path)$size))
generated_chars <- strsplit(sentence, "")[[1]]
generated_chars
readLines(path)
readLines(path, encoding = 'utf8')
readChar(path, file.info(path)$size)
readLines(path, encoding = 'utf8')
readLines(path, encoding = 'utf8')
readLines(path, encoding = 'utf-8')
install.packages("tidyverse")
readr::read_lines(path)
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
readr::read_lines(path)
paste0(readr::read_lines(path),'\n')
tolower(paste0(readr::read_lines(path),'\n', collapse = ''))
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
generated_text
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting_last.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting_last.R')
model
save_model_hdf5(model, '5book30epochs.h5', overwrite = TRUE, include_optimizer = TRUE)
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
e = c('a', 'b', 'c')
paste0(e,collapse = '')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting_last.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting_last.R')
save_model_hdf5(model, '5book40epochs.h5', overwrite = TRUE, include_optimizer = TRUE)
model %>%
fit(x, y,
batch_size = 128,
epochs = 10,
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "loss",
patience = 2,
factor = 0.7
)
)
)
save_model_hdf5(model, '5book50epochs.h5', overwrite = TRUE, include_optimizer = TRUE)
model %>%
fit(x, y,
batch_size = 128,
epochs = 10,
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "loss",
patience = 2,
factor = 0.7
)
)
)
model %>%
fit(x, y,
batch_size = 128,
epochs = 10,
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "loss",
patience = 2,
factor = 0.7
)
)
)
save_model_hdf5(model, '5book70epochs.h5', overwrite = TRUE, include_optimizer = TRUE)
model %>%
fit(x, y,
batch_size = 128,
epochs = 10,
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "loss",
patience = 2,
factor = 0.7
)
)
)
save_model_hdf5(model, '5book80epochs.h5', overwrite = TRUE, include_optimizer = TRUE)
model %>%
fit(x, y,
batch_size = 128,
epochs = 10,
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "loss",
patience = 1,
factor = 0.5
)
)
)
library(keras)
load('arrays.rdata')
model = load_model_hdf5('5book80epochs.h5')
model %>%
fit(x, y,
batch_size = 128,
epochs = 10,
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "loss",
patience = 1,
factor = 0.5
)
)
)
save_model_hdf5(model, '5book90epochs.h5', overwrite = TRUE, include_optimizer = TRUE)
model %>%
fit(x, y,
batch_size = 128,
epochs = 10,
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "loss",
patience = 1,
factor = 0.5
)
)
)
save_model_hdf5(model, '5book100epochs.h5', overwrite = TRUE, include_optimizer = TRUE)
model %>%
fit(x, y,
batch_size = 128,
epochs = 10,
callbacks = list(
callback_reduce_lr_on_plateau(
monitor = "loss",
patience = 1,
factor = 0.5
)
)
)
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/fitting3.R')
source('C:/Users/qtckp/OneDrive/Рабочий стол/RomanDisease/Нейронка из России/Том 5/continue_text.R')
